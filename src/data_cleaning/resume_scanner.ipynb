{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy \n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(dirname):\n",
    "    \"\"\"\n",
    "    Get employee names, store ids and filenames\n",
    "    \"\"\"\n",
    "    employee_names = []\n",
    "    store_ids = []\n",
    "    filepaths = []\n",
    "    uids = []\n",
    "    for root, dirs, files in os.walk(dirname):\n",
    "        for item in files:\n",
    "            if \".xlsx\" in item:\n",
    "                skip=True\n",
    "                continue\n",
    "            else:\n",
    "                filename = os.path.join(root, item)\n",
    "                filepaths.append(filename)\n",
    "                item = re.sub('[\\s]+', ' ', \n",
    "                              re.sub('^\\s\\-\\s', ' - ', \n",
    "                                     re.sub('[\\(\\)]+', ' - ', item)))\n",
    "                item = re.sub(' - not formatted', ' ', item)\n",
    "                item = re.sub('(\\s\\-)[A-Z0-9]', ' - ', item)\n",
    "                #item = re.sub('[A-Z0-9](\\-\\s)[A-Z0-9]', ' - ', item)\n",
    "                item = re.sub('.pdf', ' ', item)\n",
    "                item = re.sub('.rtf', ' ', item)\n",
    "                item = re.sub('.doc[x]*', ' ', item)\n",
    "                item = re.sub('[\\s]+', ' ', item)\n",
    "                #id = re.findall('[A-Z0-9]{3}', item)\n",
    "                splits = item.split(\" - \")\n",
    "                employee_name = splits[0]\n",
    "                #print(employee_name)\n",
    "                #print(item)\n",
    "                if len(splits) != 1:\n",
    "                    #print(item)\n",
    "                    store_id = splits[1]\n",
    "                    if len(splits) == 3:\n",
    "                        uid = splits[2]\n",
    "                    else: \n",
    "                        uid = ''\n",
    "                        print(employee_name, \"don't have uid\")\n",
    "                    #print(store_id)\n",
    "                else: \n",
    "                    store_id = ''\n",
    "                    print(employee_name, \"don't have store id\")\n",
    "                #print(uid)\n",
    "                employee_names.append(employee_name)\n",
    "                store_ids.append(store_id) \n",
    "                uids.append(uid)\n",
    "    #print(\"get names: finished\")\n",
    "    return employee_names, store_ids, filepaths, uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tika_parser(file_path):\n",
    "    file_data = parser.from_file(file_path)\n",
    "    text = file_data['content']\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_table(dirname):\n",
    "    dirpath = dirname\n",
    "    employee_names, store_ids, filepaths, uids = get_names(dirpath)\n",
    "    all_dict = {\"employee_name\":[], \"store\":[], \"raw_resume\":[], \"uid\":[], \"filename\":[]}\n",
    "    useless = 0\n",
    "    useless_lst = []\n",
    "    for i in range(len(filepaths)):\n",
    "        try:\n",
    "            clear_output(wait=True)\n",
    "            employee_name = employee_names[i]\n",
    "            store_id = store_ids[i]\n",
    "            uid = uids[i]\n",
    "            path = filepaths[i]\n",
    "            resume = tika_parser(path)\n",
    "            if \"Scanned by CamScanner\" in resume:\n",
    "                useless += 1\n",
    "                useless_lst.append(employee_name)\n",
    "            all_dict[\"employee_name\"].append(employee_name)\n",
    "            all_dict[\"store\"].append(store_id)\n",
    "            all_dict[\"raw_resume\"].append(resume)\n",
    "            all_dict[\"uid\"].append(uid)\n",
    "            all_dict[\"filename\"].append(path)\n",
    "            print(\"Current progress:\", i, \"/\", len(filepaths)-1, np.round((i+1)/len(filepaths)*100, 2), \"%\")\n",
    "            print(\"useless (scanned):\", str(useless), \"/\", len(filepaths)-1, np.round(useless/len(filepaths)*100, 2), \"%\")\n",
    "            print(\"finished\", employee_name)\n",
    "            print(\"scanned:\", useless_lst)\n",
    "        except TypeError:\n",
    "            continue\n",
    "    return pd.DataFrame(all_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start extracting resumes\n",
    "- all resumes used are due 05/08/2020 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resume folder path \n",
    "dirpath = \"C:/Users/NIV/Documents/02-HR-project/Career Builder (Resumes)/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current progress: 562 / 562 100.0 %\n",
      "useless (scanned): 6 / 562 1.07 %\n",
      "finished Yan, Xu\n",
      "scanned: ['Guilbault, Derek', 'Abualkhair, Mohd', 'Aguiar, Daniel', 'Gonzague, Aaron', 'Sukhiani, Salman', 'Tremblay, Shawnee']\n"
     ]
    }
   ],
   "source": [
    "# run \n",
    "df = convert_to_table(dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish extracting resumes then start modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_space(string):\n",
    "    if string !=\"\" and string[-1] == ' ':\n",
    "        string = string[:-1]\n",
    "    if string !=\"\" and string[-3:] == 'FRE':\n",
    "        string = string[:-4]\n",
    "    return string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.employee_name = df.employee_name.apply(remove_last_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually modify tables for joining \n",
    "# Drop duplicate Momin, Anil\n",
    "df = df.drop(index=297)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.iloc[300,0] = \"Muhoza Juste\"\n",
    "df.iloc[300,1] = \"WW 353\"\n",
    "df.iloc[300,3] = \"N5M\"\n",
    "\n",
    "df.iloc[175, 0] = \"Harvey - Jones, Derrick\"\n",
    "df.iloc[175,1] = \"TB 423\"\n",
    "df.iloc[175,3] = \"MYY\"\n",
    "\n",
    "df.iloc[205,0] = \"Kaur, Ramandeep*\"\n",
    "\n",
    "# Akash, Sadana -> Sadana, Akash\n",
    "df.iloc[14, 0] = \"Sadana, Akash\"\n",
    "# Bell, Sarah -> Ball, Sarah\n",
    "df.iloc[62, 0] = \"Ball, Sarah\"\n",
    "# Mcgregor, Ethan -> McGregor, Ethan\n",
    "df.iloc[275, 0] = \"McGregor, Ethan\"\n",
    "# Nasir, Mohammad -> Nasir, Mohammad Humayon\n",
    "df.iloc[310, 0] = \"Nasir, Mohammad Humayon\"\n",
    "# Sohi, Jaipal -> Sohi, Jaipal Singh\n",
    "df.iloc[422, 0] = \"Sohi, Jaipal Singh\"\n",
    "# Jonaid, Naizi -> Niazi, Jonaid\n",
    "df.iloc[539, 0] = \"Niazi, Jonaid\"\n",
    "\n",
    "df.iloc[541, 0] = \"Kumta, Ajit\"\n",
    "df.iloc[541, 1] = \"TB 499\"\n",
    "df.iloc[541, 3] = \"JJB\"\n",
    "\n",
    "df.iloc[71, 0] = \"Bois, Dan Kevin\"\n",
    "df.iloc[71, 1] = \"TB 421\"\n",
    "df.iloc[71, 3] = \"MVT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matching list \n",
    "matchtable = pd.read_excel(\"C:/Users/NIV/Documents/02-HR-project/data/matching_list_maunually-checked_V1.2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join dataframes \n",
    "df2 = pd.merge(df, matchtable, how=\"left\", on=\"employee_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_name</th>\n",
       "      <th>store_x</th>\n",
       "      <th>raw_resume</th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>employee_code</th>\n",
       "      <th>store_y</th>\n",
       "      <th>ADP ID</th>\n",
       "      <th>District</th>\n",
       "      <th>Job Title Description</th>\n",
       "      <th>Hire Date</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>O'Brien, Ashley</td>\n",
       "      <td>WE 591</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td></td>\n",
       "      <td>C:/Users/NIV/Documents/02-HR-project/Career Bu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WE 591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_name  store_x  \\\n",
       "320  O'Brien, Ashley  WE 591    \n",
       "\n",
       "                                            raw_resume uid  \\\n",
       "320  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...       \n",
       "\n",
       "                                              filename employee_code store_y  \\\n",
       "320  C:/Users/NIV/Documents/02-HR-project/Career Bu...           NaN  WE 591   \n",
       "\n",
       "     ADP ID District Job Title Description Hire Date language  \n",
       "320     NaN      NaN                   NaN       NaN  English  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One employee's code can't be found\n",
    "df2[df2.employee_code.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually made changed to some very unstructured resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[145, 2] = \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n1|Page\\n\\nJASHANGANDHI\\n\\n342519 Street NW Edmonton AB.T6T2B5\\n\\nEmail:jashangandhi07@gmail.com\\n\\nCELLNUMBER–780-803-8328\\n\\nOBJECTIVE\\n\\nSeeking a challenging part time position within professional environment providing an \\n\\nopportunity for growth and career advancement using my educational and work\\n\\nexperience\\n\\nWork Experience\\n\\nSAMSUNG STORE INDIA PUNJAB\\n\\nWorked as sales associate in the Samsung store for 2 years(MARCH 2014–\\n\\nAPRIL 2016)\\n\\nWALMART STORE CANADA ALBERTA\\n\\nWorked as a sales associate for AVENTURA (DIRECTENERGY) company for 6months\\n\\nWALMART STORE CANADA ALBERTA\\n\\nWorked for walmart wireless company OSL as a bike builder\\n\\nRoles and Responsibilities:\\n\\n● Responsible for ensuring the delivery of exceptional customer service at\\n\\nall times.\\n\\n● Drive sales through an understanding of customer requirements while\\n\\nproviding an appropriate product solution\\n\\n● Generate interest and awareness by proactively soliciting existing Walmart\\n\\ncustomers Accountable for achieving operational excellence through\\n\\nongoing coaching and development of sales associates\\n\\n● Responsible for achieving all key performance indicators including\\n\\nsales, customer experience and operational targets\\n\\n● Collaborate with leadership to determine ongoing strategic action plans\\n\\nthat support all key business objectives\\n\\n● Participate in all required training, with a focus on continued personal\\n\\nand professional development\\n\\n\\n\\n\\n\\n● Answering questions regarding current customers accounts and\\n\\n offering assistance\\n\\n● Keeping track of logs and paperwork including contracts with\\n\\nsensitive information\\n\\nEDUCATION\\n\\nNORQUEST COLLEGE Edmonton,Alberta\\n\\nBusiness Administration–management candidate, SEPT 2017-CURRENT\\n\\nM.G.NPUBLIC SCHOOL Jalandhar,India\\n\\nAccounting, Marketing, Business, Maths, English, March2016-April2017\\n\\nREFERNCES\\n\\nAvailable upon Request\\n\\n\\n\"\n",
    "# Remove cover letter\n",
    "df2.iloc[481, 2] = \"\\n\\nJimmy Yang\\n\\n9 Cashmere Crescent \\n\\nMarkham, Ontario L3S 4P9\\n\\nTelephone: (416) 833-7528\\n\\nEmail: cyang0519@gmail.com\\nObjective \\n\\n\\n\\nTo broaden my customer service skill by obtaining a job as mobile sales at Costco Wholesale \\n\\nQualifications and skills \\n\\n\\n\\n· Ability to work at a fast paced environment \\n\\n· Can learn very quickly\\n· Friendly, approachable and outgoing\\n· Dealing with situation with strong interpersonal, written and verbal communication skills \\n\\n· Fluent in English, Mandarin and Cantonese \\n\\nEducation \\n\\n\\n\\nCompleted Hospitality & Tourism Administration \\n\\n2006-2008\\nCentennial College \\n\\n\\nExperience \\n\\n\\n\\nSupervisor\\n\\nAxia Café Korean and Japanese Grill Restaurant \\n\\nSep. 2005-2019\\n· Responsibilities include greeting guests, taking orders and serve food\\n· Make sure tables are set with linen, dishware and flatware\\n\\n· Operation with the cash register \\n\\n· Dealing with customer complaints and assisting their needs\\n\\nServer\\nCentennial College Banquet Hall \\n\\n\\n\\n\\n2008\\n\\n· Set banquet rooms and halls as per instructions of the event manager\\n\\n· Carrying food trays \\n· Ensure that food is replenished in a quick manner\\nReferences \\n\\n\\n\\nReferences will be available upon request / Availability 9am -9pm 7 days\\n\"\n",
    "df2.iloc[482, 2] = '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nKAYASITH \\t YANG \\t\\n204-960-4939 \\t | \\t NOYYANG@LIVE.COM \\t\\n\\t\\n\\t\\n\\n\\t OBJECTIVE \\t\\n\\nTo\\tobtain\\ta\\tposition\\tutilizing\\tprior\\texperience\\twith\\ttelecom,\\ttechnology,\\t\\ncustomer\\tservice,\\tand\\tsales.\\t\\n\\n\\t\\n\\nXPLORE \\t MOBILE \\t\\n\\nSEPTEMBER\\t2018\\t-\\tPRESENT\\t\\n\\nSALES \\t ASSOCIATE \\t\\n\\n- Assisted\\tdivested\\tcustomers\\twith\\ttheir\\ttransition\\tfrom\\tBell\\tMTS\\tand\\t\\nVirgin\\tMobile\\tto\\tXplore\\tMobile.\\t\\n\\n- Investigated\\tand\\tsolved\\ttechnical\\tissues\\tregarding\\thandsets\\tand\\ta\\t\\nbrand\\tnew\\tmobile\\tnetwork.\\t\\n\\n- Met\\toverall\\tsales\\tand\\tNPS\\tscore\\ttargets\\tset\\tby\\tmanagement.\\t\\n- Helped\\tto\\ttrain\\tand\\teducate\\tless\\texperienced\\ttelecom\\temployees.\\t\\n\\nCANADA \\t REVENUE \\t\\nAGENCY \\t\\n\\nMAY\\t2017\\t–\\tPRESENT\\t\\n\\nT 3 \\t TRUST \\t AND \\t ESTATE \\t RETURN \\t ASSESING \\t OFFICER \\t / \\t\\nDISABILITY \\t TAX \\t CREDIT \\t PROCESSING \\t CLERK \\t\\n\\n- Assessed\\tand\\tprocessed\\tT3\\treturns\\tsubmitted\\tby\\tthe\\tgeneral\\tpublic.\\t\\n- T3\\taccount\\tupkeep,\\twhich\\tincludes\\tdebit\\tand\\tcredit\\tjournal\\tentries,\\t\\n\\narrears\\tinterest\\tcalculations,\\tand\\tgeneral\\taccount\\tmaintenance.\\t\\n- Reviewed\\tthe\\twork\\tof\\tpeers\\tand\\tnew\\ttrainees.\\tAssigned\\terrors\\tto\\t\\n\\nemployees\\tif\\twork\\twas\\tnot\\tsufficient.\\t\\n- Processed\\ttaxpayer\\trequests\\tfor\\tthe\\tdisability\\ttax\\tcredit\\tto\\tpreviously\\t\\n\\nassessed\\ttax\\tyears.\\t\\n\\nROGERS \\t\\nCOMMUNICATIONS \\t\\n\\nMARCH\\t2016\\t–\\tAUGUST\\t2017\\t\\t\\n\\nSALES \\t ASSOCIATE / SMALL \\t BUSINESS \\t REPRESENTATIVE \\t\\n\\n- General\\tknowledge\\ton\\tphones,\\ttablets,\\tsmart\\twatches\\tand\\t\\naccessories.\\t\\n\\n- Met\\tsales\\ttargets\\tin\\ta\\tcompetitive\\tenvironment.\\t\\n- Ensured\\tstore\\tsmall\\tbusiness\\tactivation\\tpercentage\\twas\\ton\\tpar\\twith\\t\\n\\ncorporate\\texpectations.\\t\\n- Provided\\tcustomer\\tservice\\tand\\tproblem\\tsolve\\tto\\tfix\\tcustomer\\t\\n\\nconcerns\\tand/or\\tissues.\\t\\n\\nVALUE \\t VILLAGE \\t\\nTHRIFT \\t STORE \\t\\n\\nJULY\\t2015\\t–\\tMARCH\\t2016\\t\\t\\n\\nSALES \\t ASSOCIATE \\t\\n\\n- Ran\\tcash\\tregisters\\tand\\tguided\\tcustomers\\tthrough\\tstore\\twhen\\t\\nassistance\\twas\\tneeded.\\t\\n\\n- Accepted\\tdonations\\tand\\tunloaded\\tcustomer’s\\tcars\\twhile\\tgreeting\\t\\nthem\\ton\\tbehalf\\tof\\tthe\\tCanadian\\tDiabetes\\tAssociation.\\t\\n\\n- Unloaded\\tdonation\\ttrucks\\tand\\tmoved\\tboxes\\tfrom\\tproduction\\tareas\\t\\nto\\tstore\\tfront\\tto\\tprepare\\tfor\\tseasonal\\tset\\tups.\\t\\n\\nVALLEY \\t GARDENS \\t\\nCOMMUNITY \\t\\n\\nCENTRE \\t\\nNOVEMBER\\t2014\\t–\\t\\nNOVEMBER\\t2015\\t\\n\\nEVENT \\t CARETAKER\\t\\n\\n- Set\\tup\\tevents\\tand\\tmade\\tsure\\tthey\\tran\\thow\\tthe\\thall\\trenter\\trequested.\\t\\n- Cleaned\\tevent\\thall,\\tchange\\trooms,\\tbathrooms,\\tand\\tskate\\trooms.\\t\\n- Assisted\\tin\\tice\\trink\\tclean-up.\\t\\n\\n\\t\\n\\n\\t\\n\\n\\n\\n\\t EDUCATION \\t\\n\\nUNIVERSITY \\t OF \\t\\nMANITOBA \\t\\n\\nJANUARY\\t2013\\t–\\tAPRIL\\t2018\\t\\n\\nBACHELOR \\t OF \\t COMMERCE \\t\\n\\n- Left\\tin\\tApril\\tof\\t2018\\tas\\ta\\tresult\\tof\\ta\\tpermanent\\tjob\\toffer\\tfrom\\tthe\\t\\nCanada\\tRevenue\\tAgency.\\t\\n\\t\\n\\nKILDONAN - EAST \\t\\nCOLLEGIATE \\t\\n\\nSEPTEMBER\\t2008–\\tJUNE\\t2012\\t\\n\\nHIGH \\t SCHOOL \\t DIPLOMA \\t\\n\\n- Graduated\\tin\\tJune\\t2012\\t\\n\\t\\n\\n\\t\\n\\n\\t \\t\\n\\nREFERENCES \\t\\n\\nJULIET \\t GAGNON \\t\\n\\n\\t\\n\\t\\n\\nCANADA \\t REVENUE \\t AGENCY \\t TEAM \\t LEADER \\t\\n\\n- 204-984-7779\\t\\n\\t\\n\\nAJ \\t DE \\t LEON \\t\\n\\n\\t\\n\\n\\t\\n\\nALIA \\t CAMANONG \\t\\n\\n\\t\\n\\n\\t\\n\\nSUBHDEEP \\t SIDHU \\t\\n\\t\\n\\nROGERS \\t SUPERVISOR \\t\\n\\n- 204-955-8958\\t\\n\\n\\t\\n\\nVALUE \\t VILLAGE \\t MANAGER \\t\\n\\n- 204-881-6841\\t\\n\\n\\t\\n\\nVALLEY \\t GARDENS \\t CC \\t PRESIDENT \\t\\n\\n- 204-979-5415\\t\\n\\n\\t\\n\\n\\t\\n\\n\\t\\n\\t\\n\\n\\t\\n\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_slash_nt(text):\n",
    "    text = re.sub('[\\s]+', ' ', \n",
    "                  re.sub('[\\n\\t]', ' ', \n",
    "                         text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns of plain text, resume_bline and file_type\n",
    "df2[\"resume_text\"] = df2.raw_resume.apply(remove_slash_nt)\n",
    "df2[\"resume_bline\"] = df2.raw_resume.apply(lambda x: x.split(\"\\n\"))\n",
    "df2[\"file_type\"] = df2.filename.apply(lambda x: re.match(r\".+\\.(.*)\",x).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pdf     271\n",
       "docx    246\n",
       "doc      32\n",
       "rtf       8\n",
       "Name: file_type, dtype: int64"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at file_type distribution \n",
    "df2.file_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English          496\n",
       "French            46\n",
       "not formatted     15\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at language distribution \n",
    "df2.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[['employee_name', 'employee_code', 'store_y', 'raw_resume', 'resume_text', 'resume_bline', 'language', 'file_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.rename(columns={\"store_y\": \"store\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out English resumes \n",
    "df4 = df3[df3.language == \"English\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save two csv file (all language and english only)\n",
    "df3.to_csv(\"C:/Users/NIV/Documents/02-HR-project/05182020_all_language_resumes_V1.0.csv\", index=False)\n",
    "df4.to_csv(\"C:/Users/NIV/Documents/02-HR-project/05182020_english_resumes_V1.0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
